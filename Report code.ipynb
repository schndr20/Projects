{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curves(history):\n",
    "    \n",
    "    train_loss=history.history['loss']\n",
    "    val_loss=history.history['val_loss']\n",
    "\n",
    "    train_accuracy=history.history['acc']\n",
    "    val_accuracy=history.history['val_acc']\n",
    "\n",
    "    epochs=range(1,len(history.history['loss'])+1)\n",
    "    plt.figure(figsize=(20,7))\n",
    "    \n",
    "  # plot loss \n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(epochs,train_loss,label=\"training_loss\")\n",
    "    plt.plot(epochs,val_loss,label=\"validation_loss\")\n",
    "    plt.title(\"Loss curves\")\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend()\n",
    "\n",
    "  # plot accuracy \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(epochs,train_accuracy,label=\"training_acc\")\n",
    "    plt.plot(epochs,val_accuracy,label=\"validation_acc\")\n",
    "    plt.title(\"Accuracy curves\")\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_results(results):\n",
    "    for name ,result in results.items():\n",
    "        print('Model Name: ',name,'\\n')\n",
    "        print('Loss: {} \\tAccuracy: {}\\n'.format(result[0], result[1]))\n",
    "\n",
    "evaluation_results_collection = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create File Structure and import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after you saved the folder in your current directory, specify its path:\n",
    "original_dataset_dir = \"./data\"\n",
    "\n",
    "original_train_dir = os.path.join(original_dataset_dir, 'Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the images to the given categories\n",
    "labels_train = pd.read_csv('data/labels_training.csv', sep = ';')\n",
    "\n",
    "mapping = dict(zip(labels_train['name'], labels_train['category']))\n",
    "\n",
    "for i, filename in enumerate(os.listdir(original_train_dir)):\n",
    "    \n",
    "    if filename in mapping:\n",
    "        category = mapping[filename]\n",
    "        new_filename = category + '.' + str(i) + '.' + filename.split('.')[-1]\n",
    "        os.rename(os.path.join(original_train_dir, filename), os.path.join(original_train_dir, new_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get label Name   \n",
    "def get_Label(number):\n",
    "    labels = {0:'bralette', 1:'fullcup', 2: 'balcony', 3: 'plunge'}\n",
    "    return labels[number]\n",
    "\n",
    "\n",
    "# 0 for cat ,1 for dog\n",
    "all_categories = []\n",
    "images = os.listdir(original_train_dir)\n",
    "for file in images:\n",
    "    if file.split('.')[0] == 'bralette':\n",
    "        all_categories.append(0)\n",
    "    elif file.split('.')[0] == 'fullcup':\n",
    "        all_categories.append(1)\n",
    "    elif file.split('.')[0] == 'balcony':\n",
    "        all_categories.append(2)\n",
    "    else:\n",
    "        all_categories.append(3)\n",
    "#creat data fram to save each image with its label \n",
    "df = pd.DataFrame({\n",
    "    'image': images,\n",
    "    'category':all_categories})\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Label-File: \"  + str(len(df.loc[df['category'] == 0])) +\"\\t\" + \" Mapped images: \" + str(len(labels_train.loc[labels_train['category'] == 'bralette'])))\n",
    "print(\"Label-File: \"  + str(len(df.loc[df['category'] == 1])) +\"\\t\" + \" Mapped images: \" + str(len(labels_train.loc[labels_train['category'] == 'fullcup'])))\n",
    "print(\"Label-File: \"  + str(len(df.loc[df['category'] == 2])) +\"\\t\" + \" Mapped images: \" + str(len(labels_train.loc[labels_train['category'] == 'balcony'])))\n",
    "print(\"Label-File: \"  + str(len(df.loc[df['category'] == 3])) +\"\\t\" + \" Mapped images: \" + str(len(labels_train.loc[labels_train['category'] == 'plunge'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is where we will store the images that have been split:\n",
    "base_dir = \"./bra_split\"\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "validate_dir = os.path.join(base_dir, 'validate')\n",
    "\n",
    "\n",
    "for directory in [base_dir, train_dir, test_dir, validate_dir]:\n",
    "    \n",
    "    if not os.path.exists(directory):\n",
    "\n",
    "        os.mkdir(directory)\n",
    "        print(directory, \"created\")\n",
    "        \n",
    "\n",
    "subdirectories_bralette = [] \n",
    "subdirectories_fullcup = []\n",
    "subdirectories_balcony = []\n",
    "subdirectories_plunge = [] \n",
    "\n",
    "\n",
    "for subdirectory in [train_dir, test_dir, validate_dir]:\n",
    "    subdirectories_bralette.append(os.path.join(subdirectory, 'bralette'))\n",
    "    if not os.path.exists(os.path.join(subdirectory, 'bralette')):\n",
    "        os.mkdir(os.path.join(subdirectory, 'bralette'))\n",
    "        print(os.path.join(subdirectory, 'bralette'), \"created\")\n",
    "        \n",
    "    subdirectories_fullcup.append(os.path.join(subdirectory, 'fullcup'))\n",
    "    if not os.path.exists(os.path.join(subdirectory, 'fullcup')):\n",
    "        os.mkdir(os.path.join(subdirectory, 'fullcup'))\n",
    "        print(os.path.join(subdirectory, 'fullcup'), \"created\")\n",
    "\n",
    "    subdirectories_balcony.append(os.path.join(subdirectory, 'balcony'))\n",
    "    if not os.path.exists(os.path.join(subdirectory, 'balcony')):\n",
    "        os.mkdir(os.path.join(subdirectory, 'balcony'))\n",
    "        print(os.path.join(subdirectory, 'balcony'), \"created\")\n",
    "    \n",
    "    subdirectories_plunge.append(os.path.join(subdirectory, 'plunge'))\n",
    "    if not os.path.exists(os.path.join(subdirectory, 'plunge')):\n",
    "        os.mkdir(os.path.join(subdirectory, 'plunge'))\n",
    "        print(os.path.join(subdirectory, 'plunge'), \"created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = os.listdir(original_train_dir)\n",
    "# taking 80% as train data \n",
    "x_train, x_test1, y_train, y_test1 = train_test_split(images, df[\"category\"] ,test_size=0.2, random_state=42)\n",
    "\n",
    "# from 20% data, splitting 50% as test data and 50% as validation data\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test1, y_test1 ,test_size=0.5, random_state=42)\n",
    "\n",
    "print('Training data set size :', y_train.shape[0])\n",
    "print('Test data set size :', y_test.shape[0])\n",
    "print('Validation data set size :', y_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alternative split\n",
    "\n",
    "# images = os.listdir(original_train_dir)\n",
    "# # taking 90% as train data \n",
    "# x_train, x_test1, y_train, y_test1 = train_test_split(images, df[\"category\"] ,test_size=0.1, random_state=42)\n",
    "\n",
    "# # from 10% data, splitting 5% as test data and 95% as validation data\n",
    "# x_test, x_val, y_test, y_val = train_test_split(x_test1, y_test1 ,test_size=0.95, random_state=42)\n",
    "\n",
    "# print('Training data set size :', y_train.shape[0])\n",
    "# print('Test data set size :', y_test.shape[0])\n",
    "# print('Validation data set size :', y_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix, images in enumerate([x_train, x_test, x_val]):\n",
    "    for file in images:\n",
    "        if file.split('.')[0] == 'bralette':\n",
    "            src = os.path.join(original_train_dir, file)\n",
    "            dst = os.path.join(subdirectories_bralette[ix], file)\n",
    "            shutil.copyfile(src, dst)\n",
    "        \n",
    "        elif file.split('.')[0] == 'fullcup':\n",
    "            src = os.path.join(original_train_dir, file)\n",
    "            dst = os.path.join(subdirectories_fullcup[ix], file)\n",
    "            shutil.copyfile(src, dst)\n",
    "        \n",
    "        elif file.split('.')[0] == 'balcony':\n",
    "            src = os.path.join(original_train_dir, file)\n",
    "            dst = os.path.join(subdirectories_balcony[ix], file)\n",
    "            shutil.copyfile(src, dst)\n",
    "\n",
    "        else:\n",
    "            src = os.path.join(original_train_dir, file)\n",
    "            dst = os.path.join(subdirectories_plunge[ix], file)\n",
    "            shutil.copyfile(src, dst)\n",
    "\n",
    "    print(len(os.listdir(subdirectories_bralette[ix])), \" bralette copied to:\", subdirectories_bralette[ix])\n",
    "    print(len(os.listdir(subdirectories_fullcup[ix])), \" fullcup copied to:\", subdirectories_fullcup[ix])\n",
    "    print(len(os.listdir(subdirectories_balcony[ix])), \" balcony copied to:\", subdirectories_balcony[ix])\n",
    "    print(len(os.listdir(subdirectories_plunge[ix])), \" plunge copied to:\", subdirectories_plunge[ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "plt.suptitle(\"Train Images Bralette\", fontsize=20)\n",
    "counter =0\n",
    "\n",
    "for i,img in enumerate(os.listdir(subdirectories_bralette[0]))  :\n",
    "        plt.subplot(5,5,i+1)\n",
    "\n",
    "        full_image= plt.imread(os.path.join(original_train_dir,img))\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(full_image, cmap=plt.cm.binary) \n",
    "        if i == 24:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "plt.suptitle(\"Train Images Balcony\", fontsize=20)\n",
    "counter =0\n",
    "\n",
    "for i,img in enumerate(os.listdir(subdirectories_balcony[0]))  :\n",
    "        plt.subplot(5,5,i+1)\n",
    "\n",
    "        full_image= plt.imread(os.path.join(original_train_dir,img))\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(full_image, cmap=plt.cm.binary) \n",
    "        if i == 24:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "plt.suptitle(\"Train Images Fullcup\", fontsize=20)\n",
    "counter =0\n",
    "\n",
    "for i,img in enumerate(os.listdir(subdirectories_fullcup[0]))  :\n",
    "        plt.subplot(5,5,i+1)\n",
    "\n",
    "        full_image= plt.imread(os.path.join(original_train_dir,img))\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(full_image, cmap=plt.cm.binary) \n",
    "        if i == 24:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "plt.suptitle(\"Train Images Plunge\", fontsize=20)\n",
    "counter =0\n",
    "\n",
    "for i,img in enumerate(os.listdir(subdirectories_plunge[0]))  :\n",
    "        plt.subplot(5,5,i+1)\n",
    "\n",
    "        full_image= plt.imread(os.path.join(original_train_dir,img))\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(full_image, cmap=plt.cm.binary)\n",
    "        if i == 24:\n",
    "            break "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,     # sampling size in each group \n",
    "        classes = ['bralette', 'fullcup', 'balcony', 'plunge'],\n",
    "        class_mode='categorical')\n",
    "\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validate_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        classes = ['bralette', 'fullcup', 'balcony', 'plunge'],\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_batch, labels_batch in train_generator:\n",
    "    print('data batch shape:', data_batch.shape)\n",
    "    print('labels batch shape:', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Reshape\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=25,\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical',\n",
    "        classes = ['bralette', 'fullcup', 'balcony', 'plunge'])\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validate_dir,\n",
    "        target_size=(150, 150),\n",
    "        color_mode='rgb',\n",
    "        batch_size=25,\n",
    "        class_mode='categorical',\n",
    "        classes = ['bralette', 'fullcup', 'balcony', 'plunge'])\n",
    "\n",
    "network = models.Sequential()\n",
    "reshape_layer = Reshape((150 * 150 * 3,))\n",
    "network.add(reshape_layer)\n",
    "network.add(layers.Dense(128, activation='relu', input_shape=(150 * 150 * 3,)))\n",
    "network.add(layers.Dense(256, activation='relu'))\n",
    "network.add(layers.Dense(512, activation='relu'))\n",
    "network.add(layers.Dense(128, activation='relu'))\n",
    "network.add(layers.Dense(4, activation='softmax'))\n",
    "\n",
    "\n",
    "network.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(learning_rate=0.0003),\n",
    "              metrics=['acc'])\n",
    "\n",
    "\n",
    "# number of samples in the training and validation sets\n",
    "train_samples = len(train_generator.filenames)\n",
    "val_samples = len(validation_generator.filenames)\n",
    "\n",
    "# Set the batch size\n",
    "batch_size = 25\n",
    "\n",
    "# Calculation of the the steps per epoch and validation steps\n",
    "steps_per_epoch = train_samples // batch_size\n",
    "validation_steps = val_samples // batch_size\n",
    "\n",
    "\n",
    "# Train the model\n",
    "history_network = network.fit(\n",
    "  train_generator,\n",
    "  steps_per_epoch=steps_per_epoch,      \n",
    "  epochs=30,\n",
    "  validation_data=validation_generator,\n",
    "  validation_steps=validation_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(history_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data using the test_generator\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    classes = ['bralette', 'fullcup', 'balcony', 'plunge'],\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = network.evaluate(test_generator, steps=len(test_generator))\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save results\n",
    "\n",
    "model_result = (test_loss, test_acc)\n",
    "\n",
    "evaluation_results_collection.update({\"network_model\":model_result}) \n",
    "\n",
    "evaluation_results(evaluation_results_collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic CNN - Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,     # sampling size in each group \n",
    "        classes = ['bralette', 'fullcup', 'balcony', 'plunge'],\n",
    "        class_mode='categorical')\n",
    "\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validate_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        classes = ['bralette', 'fullcup', 'balcony', 'plunge'],\n",
    "        class_mode='categorical')\n",
    "\n",
    "\n",
    "basic_model = models.Sequential()\n",
    "basic_model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(150, 150, 3)))\n",
    "basic_model.add(layers.MaxPooling2D((2, 2)))\n",
    "basic_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "basic_model.add(layers.MaxPooling2D((2, 2)))\n",
    "basic_model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "basic_model.add(layers.MaxPooling2D((2, 2)))\n",
    "basic_model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "basic_model.add(layers.MaxPooling2D((2, 2)))\n",
    "basic_model.add(layers.Flatten())\n",
    "basic_model.add(layers.Dense(512, activation='relu'))\n",
    "basic_model.add(layers.Dropout(0.1))\n",
    "basic_model.add(layers.Dense(4, activation='softmax'))  \n",
    "   \n",
    "basic_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(learning_rate=1e-4),\n",
    "              metrics=['acc'])\n",
    "\n",
    "\n",
    "# number of samples in the training and validation sets\n",
    "train_samples = len(train_generator.filenames)\n",
    "val_samples = len(validation_generator.filenames)\n",
    "\n",
    "# Set the batch size\n",
    "batch_size = 20\n",
    "\n",
    "# Calculation of the the steps per epoch and validation steps\n",
    "steps_per_epoch = train_samples // batch_size\n",
    "validation_steps = val_samples // batch_size\n",
    "\n",
    "#Train the model\n",
    "history_basic_model = basic_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(history_basic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data using the test_generator\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    classes = ['bralette', 'fullcup', 'balcony', 'plunge'],\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = basic_model.evaluate(test_generator, steps=len(test_generator))\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save results\n",
    "\n",
    "model_result = (test_loss, test_acc)\n",
    "\n",
    "evaluation_results_collection.update({\"basic_cnn_model\":model_result}) \n",
    "\n",
    "evaluation_results(evaluation_results_collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frozen VGG16 - Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(weights='imagenet', include_top = False, input_shape = (150,150,3))\n",
    "\n",
    "Frozen_model = models.Sequential()\n",
    "Frozen_model.add(conv_base)\n",
    "Frozen_model.add(layers.Flatten())\n",
    "Frozen_model.add(layers.Dense(1024, activation='relu'))\n",
    "Frozen_model.add(layers.Dense(512, activation='relu'))\n",
    "Frozen_model.add(layers.Dropout(0.5))\n",
    "Frozen_model.add(layers.Dense(4, activation='softmax'))\n",
    "\n",
    "conv_base.trainable = False\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      width_shift_range=0.1,\n",
    "      height_shift_range=0.1,\n",
    "      shear_range=0.1,\n",
    "      zoom_range=0.1,\n",
    "      fill_mode='nearest'\n",
    "      )\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical',\n",
    "        classes = ['bralette', 'fullcup', 'balcony', 'plunge'])\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validate_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical',\n",
    "        classes = ['bralette', 'fullcup', 'balcony', 'plunge'])\n",
    "\n",
    "Frozen_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(learning_rate=2e-5),\n",
    "              metrics=['acc'])\n",
    "\n",
    "\n",
    "# number of samples in the training and validation sets\n",
    "train_samples = len(train_generator.filenames)\n",
    "val_samples = len(validation_generator.filenames)\n",
    "\n",
    "# Set the batch size\n",
    "batch_size = 20\n",
    "\n",
    "# Calculation of the the steps per epoch and validation steps\n",
    "steps_per_epoch = train_samples // batch_size\n",
    "validation_steps = val_samples // batch_size\n",
    "\n",
    "# Train the model\n",
    "history_Frozen_model = Frozen_model.fit(\n",
    "  train_generator,\n",
    "  steps_per_epoch=steps_per_epoch,      \n",
    "  epochs=30,\n",
    "  validation_data=validation_generator,\n",
    "  validation_steps=validation_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(history_Frozen_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data using the test_generator\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    classes = ['bralette', 'fullcup', 'balcony', 'plunge'],\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = Frozen_model.evaluate(test_generator, steps=len(test_generator))\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save results\n",
    "\n",
    "Frozen_model_result = (test_loss, test_acc)\n",
    "\n",
    "evaluation_results_collection.update({\"Frozen_model\":Frozen_model_result}) \n",
    "\n",
    "evaluation_results(evaluation_results_collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfrozen VGG16 - Model 3 (Best Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "conv_base = VGG16(weights='imagenet', include_top = False, input_shape = (180,180,3))\n",
    "\n",
    "VGG16_model = models.Sequential()\n",
    "VGG16_model.add(conv_base)\n",
    "VGG16_model.add(layers.Flatten())\n",
    "VGG16_model.add(layers.Dense(64, activation='relu'))\n",
    "VGG16_model.add(layers.Dense(4, activation='softmax'))\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      zoom_range=[0.9,1.1],\n",
    "      brightness_range = [0.8, 1.2],\n",
    "      fill_mode='nearest'\n",
    "      )\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(180, 180),\n",
    "        batch_size=25,\n",
    "        class_mode='categorical',\n",
    "        classes = ['bralette', 'fullcup', 'balcony', 'plunge'])\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validate_dir,\n",
    "        target_size=(180, 180),\n",
    "        batch_size=25,\n",
    "        class_mode='categorical',\n",
    "        classes = ['bralette', 'fullcup', 'balcony', 'plunge'])\n",
    "\n",
    "conv_base.trainable = True\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "\n",
    "VGG16_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(learning_rate=0.00001),\n",
    "              metrics=['acc'])\n",
    "\n",
    "\n",
    "# number of samples in the training and validation sets\n",
    "train_samples = len(train_generator.filenames)\n",
    "val_samples = len(validation_generator.filenames)\n",
    "\n",
    "# Set the batch size\n",
    "batch_size = 25\n",
    "\n",
    "# Calculation of the the steps per epoch and validation steps\n",
    "steps_per_epoch = train_samples // batch_size\n",
    "validation_steps = val_samples // batch_size\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Define the callbacks\n",
    "early_stop = EarlyStopping(monitor='val_acc', patience=7)\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', \n",
    "                                    save_best_only=True, \n",
    "                                    monitor='val_acc', \n",
    "                                    mode='max', \n",
    "                                    verbose=1)\n",
    "\n",
    "# Train the model\n",
    "history_VGG16 = VGG16_model.fit(\n",
    "  train_generator,\n",
    "  steps_per_epoch=steps_per_epoch,      \n",
    "  epochs=30,\n",
    "  validation_data=validation_generator,\n",
    "  validation_steps=validation_steps,\n",
    "  callbacks=[early_stop, model_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(history_VGG16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('best_model.h5')\n",
    "\n",
    "\n",
    "# Load the test data using the test_generator\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(180, 180),\n",
    "    batch_size=25,\n",
    "    classes = ['bralette', 'fullcup', 'balcony', 'plunge'],\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=len(test_generator))\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save results\n",
    "\n",
    "Model_result = (test_loss, test_acc)\n",
    "\n",
    "evaluation_results_colle\\ction.update({\"Unfrozen_model\":Model_result}) \n",
    "\n",
    "evaluation_results(evaluation_results_collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG19\n",
    "\n",
    "conv_base = VGG19(weights='imagenet', include_top = False, input_shape = (150,150,3))\n",
    "\n",
    "VGG19_model = models.Sequential()\n",
    "VGG19_model.add(conv_base)\n",
    "VGG19_model.add(layers.Flatten())\n",
    "VGG19_model.add(layers.Dense(64, activation='relu'))\n",
    "VGG19_model.add(layers.Dense(4, activation='softmax'))\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      zoom_range=[0.9,1.1],\n",
    "      brightness_range = [0.8, 1.2],\n",
    "      fill_mode='nearest'\n",
    "      )\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical',\n",
    "        classes = ['bralette', 'fullcup', 'balcony', 'plunge'])\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validate_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical',\n",
    "        classes = ['bralette', 'fullcup', 'balcony', 'plunge'])\n",
    "\n",
    "conv_base.trainable = True\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "\n",
    "VGG19_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(learning_rate=0.00001),\n",
    "              metrics=['acc'])\n",
    "\n",
    "\n",
    "# number of samples in the training and validation sets\n",
    "train_samples = len(train_generator.filenames)\n",
    "val_samples = len(validation_generator.filenames)\n",
    "\n",
    "# Set the batch size\n",
    "batch_size = 20\n",
    "\n",
    "# Calculation of the the steps per epoch and validation steps\n",
    "steps_per_epoch = train_samples // batch_size\n",
    "validation_steps = val_samples // batch_size\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Define the callbacks\n",
    "early_stop = EarlyStopping(monitor='val_acc', patience=7)\n",
    "model_checkpoint = ModelCheckpoint('best_VGG19.h5', \n",
    "                                    save_best_only=True, \n",
    "                                    monitor='val_acc', \n",
    "                                    mode='max', \n",
    "                                    verbose=1)\n",
    "\n",
    "# Train the model\n",
    "history_VGG19 = VGG19_model.fit(\n",
    "  train_generator,\n",
    "  steps_per_epoch=steps_per_epoch,      \n",
    "  epochs=30,\n",
    "  validation_data=validation_generator,\n",
    "  validation_steps=validation_steps,\n",
    "  callbacks=[early_stop, model_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(history_VGG19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('best_VGG19.h5')\n",
    "\n",
    "\n",
    "# Load the test data using the test_generator\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    classes = ['bralette', 'fullcup', 'balcony', 'plunge'],\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=len(test_generator))\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save results\n",
    "\n",
    "Model_result = (test_loss, test_acc)\n",
    "\n",
    "evaluation_results_collection.update({\"VGG19_model\":Model_result}) \n",
    "\n",
    "evaluation_results(evaluation_results_collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "conv_base = ResNet50(weights='imagenet', include_top = False, input_shape = (150,150,3))\n",
    "\n",
    "ResNet50_model = models.Sequential()\n",
    "ResNet50_model.add(conv_base)\n",
    "ResNet50_model.add(layers.Flatten())\n",
    "ResNet50_model.add(layers.Dense(64, activation='relu'))\n",
    "ResNet50_model.add(layers.Dense(4, activation='softmax'))\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      zoom_range=[0.9,1.1],\n",
    "      brightness_range = [0.8, 1.2],\n",
    "      fill_mode='nearest'\n",
    "      )\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical',\n",
    "        classes = ['bralette', 'fullcup', 'balcony', 'plunge'])\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validate_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical',\n",
    "        classes = ['bralette', 'fullcup', 'balcony', 'plunge'])\n",
    "\n",
    "conv_base.trainable = True\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "\n",
    "ResNet50_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(learning_rate=0.00001),\n",
    "              metrics=['acc'])\n",
    "\n",
    "\n",
    "# number of samples in the training and validation sets\n",
    "train_samples = len(train_generator.filenames)\n",
    "val_samples = len(validation_generator.filenames)\n",
    "\n",
    "# Set the batch size\n",
    "batch_size = 20\n",
    "\n",
    "# Calculation of the the steps per epoch and validation steps\n",
    "steps_per_epoch = train_samples // batch_size\n",
    "validation_steps = val_samples // batch_size\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Define the callbacks\n",
    "early_stop = EarlyStopping(monitor='val_acc', patience=7)\n",
    "model_checkpoint = ModelCheckpoint('best_ResNet50.h5', \n",
    "                                    save_best_only=True, \n",
    "                                    monitor='val_acc', \n",
    "                                    mode='max', \n",
    "                                    verbose=1)\n",
    "\n",
    "# Train the model\n",
    "history_ResNet50 = ResNet50_model.fit(\n",
    "  train_generator,\n",
    "  steps_per_epoch=steps_per_epoch,      \n",
    "  epochs=30,\n",
    "  validation_data=validation_generator,\n",
    "  validation_steps=validation_steps,\n",
    "  callbacks=[early_stop, model_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(history_ResNet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('best_resnet50.h5')\n",
    "\n",
    "\n",
    "# Load the test data using the test_generator\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    classes = ['bralette', 'fullcup', 'balcony', 'plunge'],\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=len(test_generator))\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save results\n",
    "\n",
    "Model_result = (test_loss, test_acc)\n",
    "\n",
    "evaluation_results_collection.update({\"ResNet50_model\":Model_result}) \n",
    "\n",
    "evaluation_results(evaluation_results_collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Prediction & Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (180, 180)\n",
    "\n",
    "img_dir = \"./data/Testing\"\n",
    "\n",
    "\n",
    "class_names = {\n",
    "    0: 'bralette',\n",
    "    1: 'fullcup',\n",
    "    2: 'balcony',\n",
    "    3: 'plunge'\n",
    "}\n",
    "\n",
    "predict_results=[]\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "for img_file in os.listdir(img_dir):\n",
    "    # Load the image and preprocess it\n",
    "    \n",
    "    img_path = os.path.join(img_dir, img_file)\n",
    "    img = image.load_img(img_path, target_size=img_size)\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img/255, axis=0)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(img)\n",
    "    \n",
    "    class_idx = np.argmax(predictions[0])\n",
    "    class_prob = predictions[0][class_idx]\n",
    "\n",
    "    class_name = class_names[class_idx]\n",
    "    print(f'{img_file}: {class_name} ({class_prob})')\n",
    "    predict_results.append((img_file, class_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# Define the file name and headers for the CSV file\n",
    "file_name = 'predictions_final.csv'\n",
    "field_names = ['id', 'label']\n",
    "\n",
    "# Write the predictions to the CSV file\n",
    "with open(file_name, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(field_names)\n",
    "    for prediction in predict_results:\n",
    "        writer.writerow(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
